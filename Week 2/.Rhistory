x2 <- filter(dat,Diet=='chow' & Sex=='F') %>% filter(Bodyweight) %>% unlist()
x2 <- filter(dat,Diet=='chow' & Sex=='F') %>% select(Bodyweight) %>% unlist()
y2 <- filter(dat, DIet=='hf' & Sex=='M') %>% select(Bodyweight) %>% unlist()
y2 <- filter(dat, DIet=='hf' & Sex=='F') %>% select(Bodyweight) %>% unlist()
y2 <- filter(dat, Diet=='hf' & Sex=='F') %>% select(Bodyweight) %>% unlist()
set.seed(1)
X2 <- sample(x2,25)
set.seed(1)
Y2 <- sample(y2.25)
Y2 <- sample(y2,25)
abs((mean(y) - mean(x) - (mean(Y) - mean(X))))
abs( ( mean(y) - mean(x) ) - ( mean(Y) - mean(X) ) )
x2 <- filter(dat, Sex=='F' & Diet=='chow') %>% select(Bodyweight) %>% unlist()
y2 <- filter(dat, Sex=='F'& Diet=='hf') %>% select(Bodyweight) %>% unlist()
set.seed(1)
X2 <- sample(x2,25)
set.seed(1)
Y2 <- sample(y2,25)
abs((mean(y) - mean(x) - (mean(Y) - mean(X))))
# The Normal Distribution
library(dplyr)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url,destfile=filename)
x <- unlist(read.csv(filename))
set.seed(1)
n = 1000
averages5 <- vector("numeric",n)
for (i in 1:n){
averages[i] <- sample(x,5)
}
set.seed(1)
n = 1000
averages5 <- vector("numeric",n)
for (i in 1:n){
averages5[i] <- sample(x,5)
}
set.seed(1)
n = 1000
averages50 <- vector("numeric",n)
for (i in 1:n){
averages50[i] <- sample(x,50)
}
# For the last set of averages, the ones obtained from a sample size of 50,
# what proportion are between 23 and 25?
mean(averages50 > 23 & averages50 < 25)
mean(averages50 < 25 & averages50 > 23)
averages5
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url,destfile=filename)
x <- unlist(read.csv(filename))
x <- na.omit(x)
set.seed(1)
n = 1000
averages5 <- vector("numeric",n)
for (i in 1:n){
averages5[i] <- sample(x,5)
}
set.seed(1)
n = 1000
averages50 <- vector("numeric",n)
for (i in 1:n){
averages50[i] <- sample(x,50)
}
# For the last set of averages, the ones obtained from a sample size of 50,
# what proportion are between 23 and 25?
mean(averages50 > 23 & averages50 < 25)
mean(averages50 < 25 & averages50 > 23)
# Now ask the same question of a normal distribution with average 23.9 and
# standard deviation 0.43.
pnorm((25 - 23.9) / 0.43) - pnorm((23 - 23.9) / 0.43)
pnorm((25-23.9) / 0.43)  - pnorm((23-23.9) / 0.43)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
# If a list of numbers has a distribution that is well approximated by the normal
# distribution, what proportion of these numbers are within one standard deviation
# away from the list's average?
pnorm(1) - pnorm(-1)
# What proportion of these numbers are within two standard deviations away
# from the list's average?
pnorm(2) - pnorm(-2)
# What proportion of these numbers are within three standard deviations away
# from the list's average?
pnorm(3) - pnorm(-3)
# Define y to be the weights of males on the control diet. What proportion
# of the mice are within one standard deviation away from the average
# weight (remember to use popsd for the population sd)?
y <- filter(dat,(Sex=='M') & (Diet=='chow')) %>% select(Bodyweight) %>% unlist()
# Central Limit Theorem (CLT)
library(rafalib)
z <- (y - mean(y)) / popsd(y)
mean(abs(Z) <= 1)
mean(abs(z) <= 1)
# What proportion of these numbers are within two standard deviations away
# from the list's average?
mean(abs(z) <= 2)
# What proportion of these numbers are within three standard deviations away
# from the list's average?
mean(abs(z) <= 3)
mypar(2,2)
y <- filter(dat, Sex=="M" & Diet=="chow") %>% select(Bodyweight) %>% unlist
z <- ( y - mean(y) ) / popsd(y)
qqnorm(z);abline(0,1)
y <- filter(dat, Sex=="F" & Diet=="chow") %>% select(Bodyweight) %>% unlist
z <- ( y - mean(y) ) / popsd(y)
qqnorm(z);abline(0,1)
y <- filter(dat, Sex=="M" & Diet=="hf") %>% select(Bodyweight) %>% unlist
z <- ( y - mean(y) ) / popsd(y)
qqnorm(z);abline(0,1)
y <- filter(dat, Sex=="F" & Diet=="hf") %>% select(Bodyweight) %>% unlist
z <- ( y - mean(y) ) / popsd(y)
qqnorm(z);abline(0,1)
y <- filter(dat, Sex=="M" & Diet=="chow") %>% select(Bodyweight) %>% unlist
avgs <- replicate(10000, mean( sample(y, 25)))
mypar(1,2)
hist(avgs)
qqnorm(avgs)
qqline(avgs)
mean(avgs)
sd(avgs)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
library(rafalib)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
library(rafalib)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control <- sample(population,12)
treatment <- sample(population.12)
nulls[i] <- mean(control) - mean(treatment)
}
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- basename(url)
download(url, destfile=filename)
population <- na.omit( read.csv(filename) )
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control <- sample(population,12)
treatment <- sample(population.12)
nulls[i] <- mean(control) - mean(treatment)
}
View(population)
View(dat)
View(population)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
population <- filter(dat,Diet=='chow') %>% select(Bodyweight) %>% unlist()
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control <- sample(population,12)
treatment <- sample(population.12)
nulls[i] <- mean(control) - mean(treatment)
}
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control <- sample(population,12)
treatment <- sample(population,12)
nulls[i] <- mean(control) - mean(treatment)
}
obs <- mean(treatment) - mean(control)
mean(abs(nulls) > obs)
obs <- mean(population)
mean(abs(nulls) > obs)
obs
nulls
control
treatment
View(dat)
library(dplyr)
dat <- read.csv('femaleMiceWeights.csv')
dat <- read.csv('femaleMiceWeights.csv')
control <- filter(dat,Diet=='chow') %>% select(Bodyweight) %>% unlist()
treatment <- filter(dat,Diet=='hf') %>% select(Bodyweight) %>% unlist()
N <- length(treatment)
obs <- mean(treatment) - mean(control)
se <- sqrt(var(treatment) / N + var(control) / N)
tstat <- obs / se
tstat
1 - pnorm(tstat)
2 * (1 - pnorm(tstat))
?t.test
View(dat)
t.test(Diet~Bodyweight,data=dat)
t.test(dat)
population <- read.csv('femaleControlsPopulation.csv')
population <- unlist(population)
n < 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control2 <- sample(population,3)
treatment2 <- sample(population,3)
nulls[i] <- mean(treatment2) - mean(control2)
}
n < 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control2 <- sample(population,3)
treatment2 <- sample(population,3)
nulls[i] <- mean(treatment2) - mean(control2)
}
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control2 <- sample(population,3)
treatment2 <- sample(population,3)
nulls[i] <- mean(treatment2) - mean(control2)
}
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control2 <- sample(population,N)
treatment2 <- sample(population,N)
nulls[i] <- mean(treatment2) - mean(control2)
}
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control2 <- sample(population,N)
treatment2 <- sample(population,N)
nulls[i] <- (mean(treatment2) - mean(control2)) / se
}
mean(abs(nulls) > obs)
library(rafalib)
mypar()
qqnorm(nulls)
mypar()
qqnorm(nulls)
qqline(nulls)
mypar()
qqnorm(nulls)
abline(0,1)
qqline(nulls)
n <- 10000
nulls2 <- vector("numeric",n)
for (i in 1:n){
control3 <- sample(population,3)
treatment3 <- sample(population,3)
nulls2[i] <- (mean(treatment2) - mean(control2)) / se
}
mypar()
qqnorm(nulls2)
abline(0,1)
qqline(nulls2)
n <- 10000
nulls2 <- vector("numeric",n)
for (i in 1:n){
control3 <- sample(population,3)
treatment3 <- sample(population,3)
nulls2[i] <- (mean(treatment3) - mean(control3)) / se
}
mypar()
qqnorm(nulls2)
abline(0,1)
qqline(nulls2)
n <- 10000
nulls <- vector("numeric",n)
for (i in 1:n){
control2 <- sample(population,N)
treatment2 <- sample(population,N)
se <- sqrt(var(treatment) / N + var(control) / N)
nulls[i] <- (mean(treatment2) - mean(control2)) / se
}
mean(abs(nulls) > obs)
mypar()
qqnorm(nulls)
abline(0,1)
qqline(nulls)
n <- 10000
nulls2 <- vector("numeric",n)
for (i in 1:n){
control3 <- sample(population,3)
treatment3 <- sample(population,3)
se <- sqrt(var(treatment) / N + var(control) / N)
nulls2[i] <- (mean(treatment3) - mean(control3)) / se
}
mypar()
qqnorm(nulls2)
abline(0,1)
qqline(nulls2)
n <- 10000
nulls2 <- vector("numeric",n)
for (i in 1:n){
control3 <- sample(population,3)
treatment3 <- sample(population,3)
se <- sqrt(var(treatment) / 3 + var(control) / 3)
nulls2[i] <- (mean(treatment3) - mean(control3)) / se
}
mypar()
qqnorm(nulls2)
abline(0,1)
qqline(nulls2)
n <- 10000
nulls2 <- vector("numeric",n)
for (i in 1:n){
control3 <- sample(population,3)
treatment3 <- sample(population,3)
se <- sqrt(var(treatment3) / 3 + var(control3) / 3)
nulls2[i] <- (mean(treatment3) - mean(control3)) / se
}
mypar()
qqnorm(nulls2)
abline(0,1)
qqline(nulls2)
dat <- read.csv('femaleMiceWeights.csv')
control <- filter(dat,Diet=='chow') %>% select(Bodyweight) %>% unlist()
treatment <- filter(dat,Diet=='hf') %>% select(Bodyweight) %>% unlist()
t.test(treatment,control)
2 * (1 - pnorm(tstat))
tstat <- obs / se
tstat
se <- sqrt(var(treatment) / N + var(control) / N)
se
qqnorm(control)
qqline(control)
qqnorm(treatment)
qqline(treatment)
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- "femaleMiceWeights.csv"
if(!file.exists("femaleMiceWeights.csv")) download(url,destfile=filename)
dat2 <- read.csv(filename)
x = sample((1:6,100,replace=TRUE)
x = sample(1:6,100,replace=TRUE)
x
x <- sample(1:6,n,replace = TRUE)
# We want to roll n dice 10,000 times and keep these proportions.
# This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n.
# So according to CLT z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal
# with mean 0 and SD 1. Set the seed to 1, then use replicate to perform the
# simulation, and report what proportion of times z was larger than 2 in
# absolute value (CLT says it should be about 0.05).
set.seed(1)
n <- 10000
n <- 100
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- z = (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
p <- 1/6
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- z = (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
mean(abs(zs) > 2)
qqnorm(zs)
qqline(zs)
z
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
z
set.seed(1)
n <- 100
p <- 1/6
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
z
z
set.seed(1)
n <- 5
p <- 0.5
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
z
mean(abs(zs) > 2)
mean(abs(zs) > 2)
set.seed(1)
n <- 30
p <- 0.5
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
z
mean(abs(zs) > 2)
set.seed(1)
n <- 30
p <- 0.01
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
z
mean(abs(zs) > 2)
set.seed(1)
n <- 100
p <- 0.01
zs <- replicate(1000,{
x <- sample(1:6,n,replace = TRUE)
z <- (mean(x==6) - p) / sqrt(p*(1-p)/n)
})
z
mean(abs(zs) > 2)
# Define the parameter  μX  as the average of the control population.
# We estimate this parameter with the sample average  X¯ .
# What is the sample average?
X <- filter(dat,Diet=='chow') %>% select(Bodyweight) %>% unlist()
Y <- filter(dat,Diet=='hf') %>% select(Bodyweight) %>% unlist()
mean(X)
sqrt(12)
sd(X)
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
pnorm(2/sd(x) * sqrt(12))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
1 - pnorm(2/sd(x) * sqrt(12))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2*(1 - pnorm(2/sd(x) * sqrt(12)))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2*(1 - pnorm(2/sd(x)) * sqrt(12))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
pnorm(2/sd(x) * sqrt(12))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
1 - pnorm(2/sd(x) * sqrt(12))
2 * ( 1-pnorm(2/sd(X) * sqrt(12) ) )
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2 * (1-pnorm(2/sd(x) * sqrt(12)))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2 * (1-pnorm(2/sd(x) * sqrt(12)))
2 * ( 1-pnorm(2/sd(X) * sqrt(12) ) )
2 * (1-pnorm(2/sd(X) * sqrt(12)))
2 * (1-pnorm(2/sd(X) * sqrt(12)))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2 * (1-pnorm(2/sd(x) * sqrt(12)))
2 * (1-pnorm(2/sd(X) * sqrt(12)))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2 * (1-pnorm(2/sd(x) * sqrt(12)))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2 * (1-pnorm(2/sd(X) * sqrt(12)))
# Use the CLT to approximate the probability that our estimate  X¯
# is off by more than 2 grams from  μX .
2 * (1-pnorm(2/sd(X) * sqrt(12)))
mean(X)
mean(abs(zs) > 2)
mean(abs(zs) > 2)
z
sqrt((sd(X)/12) + (sd(Y) /12))
sqrt((var(X)/12) + (var(Y) /12))
(mean(control) - mean(treatment)) / se
# Define the parameter  μX  as the average of the control population.
# We estimate this parameter with the sample average  X¯ .
# What is the sample average?
X <- filter(dat,Diet=='chow') %>% select(Bodyweight) %>% unlist()
# So now we can compute  Y¯−X¯  as well as an estimate of this standard error
# and construct a t-statistic. What number is this t-statistic?
se <- sqrt((var(X)/12) + (var(Y) /12))
(mean(control) - mean(treatment)) / se
# So now we can compute  Y¯−X¯  as well as an estimate of this standard error
# and construct a t-statistic. What number is this t-statistic?
se <- sqrt((var(X)/12) + (var(Y) /12))
(mean(treatment) - mean(control)) / se
z <- (mean(treatment) - mean(control)) / se
# Now we are ready to compute a p-value using the CLT. What is the
# probability of observing a quantity as large as what we computed in 9,
# when the null distribution is true?
2 * (1 - pnorm(z))
# In practice, we can't check the assumption because we only get to see 1
# outcome (which you computed above). As a result, if this approximation is off,
# so is our p-value. As described earlier, there is another approach that does
# not require a large sample size, but rather that the distribution of the
# population is approximately normal. We don't get to see this distribution
# so it is again an assumption, although we can look at the distribution of
# the sample with qqnorm(X) and qqnorm(Y). If we are willing to assume this,
# then it follows that the t-statistic follows t-distribution.
# What is the p-value under the t-distribution approximation?
# Hint: use the t.test function.
t.test(control,treatment)
